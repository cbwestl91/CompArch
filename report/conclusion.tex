All in all the implentation of the prefetcher is comparable to an implementation based on the more probabilistic principle of locality. While the prefetcher detailed in this report attempts to map all of the the most frequent prefetch sequences and act based on these and only these, an approach based on the principle of locality would use much of the same concept, but would assume temporal and spatial correlations instead of writing a log based on observed prefetches. The idea of mapping possible sequences directly to their assumed following address might work in a predictable environment, but does not seem to function well in a more practical environment. A more useful approach would be to cache the most frequently accessed addresses, or simply the address area around a request. 

Another reason for the prefetcher's low performance is the size of the accessed memory spaces. With so many combinations, it is not too likely that the same sequences will be frequented a lot. If the memory space was smaller, the same sequences might have been frequented more, resulting in higher accuracy. With the amount of addresses being high, the actual hits drown in the vast amount of possible sequences.

The project was a great learning experience, and has shown the importance of simulating ideas that sound like a good idea in theory. Writing the report was also a good practice in documenting the work done, and even though the prefetcher provided a poor speedup, the work done resulted in increased understanding of processors and their caches.
