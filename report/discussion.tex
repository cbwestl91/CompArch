The prefetcher resulted in a speed increase of 1\%, which is way below our expectations. While the algorithm was meant to improve the DCPT approach by removing the uncertainity of relying on the previous valid delta value, the somewhat rigid structure of the scoring system appeared to impair the adaptive nature of the original. Looking at the amount of memory accesses, it became obvious that attempting to log enough patterns in such a big address space to make a difference simply introduced unnecessary complexity. The amount of address combinations is extremely high, reducing the chance that the same patterns are visited multiple times before a mapped entry disappears to a minimum. While some of the sequences probably will be visited again in the future, all the combinations without entries and entries that are never repeated completely dominates the few good fetches, rendering the potential speed increase and accuracy negligible. 

The program counter part of the DCPT algorithm also appears to be extremely important to the quality of the fetches. This is easiest to notice in the swim benchmark, as our algorithm shows much lower performance, with no difference in the score between the normal and the unlimited combination pool size version. This suggests that the patterns are tightly connected to their respective program counters, as an increased combination pool size should benefit an algorithm struggling to keep track of a lot of different patterns. This theory is supported by the low accuracy in our implementation for this benchmark. When the unlimited pool size version of the prefetcher only performs marginally better than the restricted version, and still a lot worse than the DCPT, which supports that the correlation between program counter position and patterns is way too high to be ignored. 

One could compare the prefetcher detailed in this report with a simpler prefetcher based on the locality principle. While such a prefetcher makes a probabilistic assumption that conceding fetches will be related in some spatial or temporal manner, the prefetcher detailed here attempts to be as deterministic as possible. The margin of error allowed is implicitly much lower in the prefetcher detailed in this report, with only directly mapped sequences being prefetched. The use of spatial and temporal locality therefore seems superior, both in terms of simplicity and results.

Table \ref{table:results2} shows an attempt to increase the speedup. The size of the combination pool was multiplied by 10000, to see if this changed the behaviour. In theory, this should help avoid having sequences deleted before they were used due to the massive amount of possible sequences, but this only resulted in a speedup of 1.5\% . The lack of speed increase shows that the algorithm was in the wrong from the beginning, and that the pool size really doesn't matter much. The algorithm assumes that things happen periodically, something there is no guarantee for in the benchmarks. In addition, the vast amount of possible combinations is still out of reach.

The prefetcher is not able to determine the outcome of a combination before there's been at least one previos case of the same pattern. If all request deltas are unique, prefetches will never occur. This is especially clear in benchmark ammp shown in table \ref{table:results}. Without any proper analysis of the access patterns in the benchmark, it is hard to determine exactly how it pinpoints the weaknesses of the prefetcher. A good guess could be that pattern repetition rate is very low, while the lack of a program counter doesn't make much of a difference, since the DCPT performs pretty similarly. One huge difference that shouldn't go uncommented, is the amount of identified fetches our algorithm has compared to the DCPT. While the issued count is rather similar, the amount of attempted fetches is extreme. This is one of the points that we found the strangest during development and beta-testing; we did prefetches for almost every single memory access, and it would successfully predict the next address, but the next would be tagged as a miss, and the prefetch never reported as finished. The reason for this appears to be that every single fetch is a bit to slow, a theory which is supported by the fact that the missed prefetches actually show up as finished a bit later. A lot of experimenting was performed to figure out why this happened, and the conclusion is that the memory bus has a 30ns latency, while the time between memory accesses is 60ns. In order to get fetch a block, a signal has to be sent to the main memory, before the result is sent back, resulting in a 60ns delay plus lookup and storage overhead, which should be enough to push the result of the prefetch behind schedule. This results in a lot of issued prefetches and close to no pay-out.

A general trend through all the tests is that the accuracy and IPC of our implementations is comparable to the DCPT, while the coverage is a lot poorer. This supports our theory of the limits the small combination pool gives us. A low coverage means that we had a lot of memory accesses without prefetching compared to good prefetches. This low coverage is probably mostly because we spend a lot of time just creating elements for new combinations, and therefore avoid prefetching. The fact that the algorithm only issues a prefetch when a pattern is recognized might penalize the coverage score a bit, while the accuracy should benefit from it. These are one of the few points where we feel we actually succeeded, and the intent of the algorithm actually is reflected in the results. 

In addition to rather poor performance, the algorithm is very complex and utilizes a great deal of dynamic memory allocation, which would make a good, compact hardware implementation hard to implement. Searching algorithms in the combination pool would be hard to do fast, and a hashing function should be considered.


Further development of the algorithm should be directed towards reimplementing the program counter into the algorithm, while still keeping the scoring system. This could end up improving the DCPT algorithm, while avoiding the biggest drawbacks of the current implementation. A more dynamic and adaptive approach to the scoring system should also be able to boost the performance through changing access patterns. 


%  Why no speed increase
% Attempts to increase speed. How and why
% Comment each test
% Compare with no-limit results
% Compare with DCPT
%
%
%
