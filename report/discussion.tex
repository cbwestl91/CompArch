The prefetcher resulted in a speed increase of 1\%, which is way below our expectations. While the algorithm was meant to improve the DCPT approach by removing the uncertainity of relying on the previous valid delta value, the somewhat rigid structure of the scoring system appeared to impair the adaptive nature of the original. Looking at the amount of memory accesses, it became obvious that attempting to log enough patterns in such a big address space to make a difference simply introduced unnecessary complexity. The amount of address combinations is extremely high, reducing the chance that the same patterns are visited multiple times before a mapped entry disappears to a minimum. While some of the sequences probably will be visited again in the future, all the combinations without entries and entries that are never repeated completely dominates the few good fetches, rendering the potential speed increase and accuracy negligible. 

One could compare the prefetcher detailed in this report with a simpler prefetcher based on the locality principle. While such a prefetcher makes a probabilistic assumption that conceding fetches will be related in some spatial or temporal manner, the prefetcher detailed here attempts to be as deterministic as possible. The margin of error allowed is implicitly much lower in the prefetcher detailed in this report, with only directly mapped sequences being prefetched. The use of spatial and temporal locality therefore seems superior, both in terms of simplicity and results.

%TODO mer her

Table \ref{table:results2} shows an attempt to increase the speedup. The size of the combination pool was multiplied by 10000, to see if this changed the behaviour. In theory, this should help avoid having sequences deleted before they were used due to the massive amount of possible sequences. The lack of speed increase shows that the algorithm was in the wrong from the beginning, and tries to predict too much. It assumes that things happen periodically, something there is no guarantee for in the benchmarks. In addition, the vast amount of possible combinations is still out of reach.

The prefetcher is not able to determine the outcome of a combination before there's been at least one previos case of the same pattern. If all request deltas are unique, prefetches will never occur. This is especially clear in benchmark ammp shown in table \ref{table:results}. Without any proper analysis of the access patterns in the benchmark, it is hard to determine exactly how it pinpoints the weaknesses of the prefetcher. A good guess could be that pattern repetition rate is very low, while the lack of a program counter doesn't make much of a difference, since the DCPT performs pretty similarly. The swim benchmark clearly seperates the DCPT from our implementation, as our shows much lower performance, with no difference in the score between the normal and the unlimited element pool size version. This suggests that the patterns are tightly connected to their respective program counters, a theory that is supported by the low accuracy in our implementation.

A general trend through all the tests is that the accuracy and IPC of our implementations is comparable to the DCPT, while the coverage is a lot poorer. This supports our theory of the limits the small combination pool gives us. A low coverage means that we had a lot of memory accesses without prefetching compared to good prefetches. This low coverage is probably 

%  Why no speed increase
% Attempts to increase speed. How and why
% Comment each test
% Compare with no-limit results
% Compare with DCPT
%
%
%
